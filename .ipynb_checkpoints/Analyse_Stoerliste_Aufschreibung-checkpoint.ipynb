{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be11b931",
   "metadata": {},
   "source": [
    "# Analyse Störliste – Blatt „Aufschreibung“\n",
    "\n",
    "Dieses Notebook:\n",
    "1. lädt die Excel-Datei,\n",
    "2. entfernt alle **leeren Zeilen**, die **ab der Spalte „Dauer Org-Mangel“** (und alle folgenden Spalten) **keine Daten** enthalten,\n",
    "3. bereitet Zeit-/Dauerfelder auf und\n",
    "4. analysiert **Stoßzeiten**, **Maschinen/Stationen** und **Fehlerursachen** inkl. Auffälligkeiten bei der **Ausfalldauer**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f8de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Datei-Pfad (im gleichen Ordner wie das Notebook oder anpassen)\n",
    "FILE_PATH = \"Stoerliste_Heckrungenanlage_2023_NEU.xlsx\"\n",
    "SHEET_NAME = \"Aufschreibung\"\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba7891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Laden ---\n",
    "df_raw = pd.read_excel(FILE_PATH, sheet_name=SHEET_NAME)\n",
    "\n",
    "print(\"Rohdaten:\", df_raw.shape)\n",
    "display(df_raw.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc573424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Spaltennamen normalisieren (Zeilenumbrüche/Mehrfachspaces entfernen) ---\n",
    "df = df_raw.copy()\n",
    "df.columns = [re.sub(r\"\\s+\", \" \", str(c).strip()) for c in df.columns]\n",
    "\n",
    "# Zielspalte finden (robust, falls in Excel Zeilenumbrüche/Spaces anders sind)\n",
    "target_pattern = re.compile(r\"^Dauer\\s*Org-?Mangel$\", re.IGNORECASE)\n",
    "start_col = None\n",
    "for c in df.columns:\n",
    "    if target_pattern.match(c):\n",
    "        start_col = c\n",
    "        break\n",
    "\n",
    "if start_col is None:\n",
    "    # Fallback: suche nach beiden Wörtern\n",
    "    candidates = [c for c in df.columns if (\"Dauer\" in c) and (\"Org\" in c) and (\"Mangel\" in c)]\n",
    "    if candidates:\n",
    "        start_col = candidates[0]\n",
    "\n",
    "if start_col is None:\n",
    "    raise ValueError(\"Spalte 'Dauer Org-Mangel' konnte nicht gefunden werden. Bitte Spaltennamen prüfen.\")\n",
    "\n",
    "start_idx = list(df.columns).index(start_col)\n",
    "cols_from = list(df.columns)[start_idx:]\n",
    "\n",
    "print(\"Startspalte:\", start_col)\n",
    "print(\"Spalten ab Startspalte:\", cols_from)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1bccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Leere Zeilen entfernen: wenn ab Startspalte (inkl.) ALLES leer ist ---\n",
    "df_clean = df.copy()\n",
    "\n",
    "# Leere Strings -> NA (nur in object/string-Spalten)\n",
    "for c in cols_from:\n",
    "    if df_clean[c].dtype == object:\n",
    "        df_clean[c] = df_clean[c].astype(\"string\").str.strip()\n",
    "        df_clean.loc[df_clean[c].isin([\"\", \"nan\", \"NaN\"]), c] = pd.NA\n",
    "\n",
    "mask_keep = df_clean[cols_from].notna().any(axis=1)\n",
    "df_clean = df_clean.loc[mask_keep].copy()\n",
    "\n",
    "print(\"Nach dem Entfernen leerer Zeilen:\", df_clean.shape)\n",
    "display(df_clean.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e116b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: bereinigte Daten speichern\n",
    "df_clean.to_csv(\"Aufschreibung_clean.csv\", index=False)\n",
    "df_clean.to_excel(\"Aufschreibung_clean.xlsx\", index=False)\n",
    "\n",
    "print(\"Gespeichert als: Aufschreibung_clean.csv / Aufschreibung_clean.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e77081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Aufbereitung: Zeitspalten, Ausfalldauer (min) ---\n",
    "# Dauer-Spalten (in Minuten) – ggf. anpassen, falls andere Namen vorkommen\n",
    "duration_cols = [\n",
    "    \"Dauer Org-Mangel\",\n",
    "    \"Dauer Anlagen-Ausfall\",\n",
    "    \"Dauer Anlagen-Ausfall intern\",\n",
    "    \"Dauer Logistik- Defizite\",\n",
    "]\n",
    "for c in duration_cols:\n",
    "    if c in df_clean.columns:\n",
    "        df_clean[c] = pd.to_numeric(df_clean[c], errors=\"coerce\")\n",
    "\n",
    "df_clean[\"Downtime_min\"] = df_clean[duration_cols].sum(axis=1, skipna=True)\n",
    "\n",
    "# Zeit robust in Sekunden umwandeln (Zeit-Objekte oder Strings)\n",
    "import datetime as dt\n",
    "def safe_time_to_seconds(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, dt.time):\n",
    "        return x.hour*3600 + x.minute*60 + x.second\n",
    "    s = str(x).strip()\n",
    "    # 'HH:MM' oder 'HH:MM:SS'\n",
    "    if re.match(r\"^\\d{1,2}:\\d{2}(:\\d{2})?$\", s):\n",
    "        parts = s.split(\":\")\n",
    "        h = int(parts[0]); m = int(parts[1]); sec = int(parts[2]) if len(parts) > 2 else 0\n",
    "        return h*3600 + m*60 + sec\n",
    "    # Excel kann Zeiten als Tagesbruchteil speichern\n",
    "    if re.match(r\"^\\d+(\\.\\d+)?$\", s):\n",
    "        frac = float(s)\n",
    "        return int(round(frac*24*3600))\n",
    "    return np.nan\n",
    "\n",
    "date_norm = pd.to_datetime(df_clean[\"Datum\"], errors=\"coerce\").dt.normalize()\n",
    "\n",
    "start_seconds = df_clean[\"Zeit von\"].apply(safe_time_to_seconds)\n",
    "end_seconds   = df_clean[\"Zeit bis\"].apply(safe_time_to_seconds)\n",
    "\n",
    "df_clean[\"Start\"] = date_norm + pd.to_timedelta(start_seconds, unit=\"s\")\n",
    "df_clean[\"End\"]   = date_norm + pd.to_timedelta(end_seconds, unit=\"s\")\n",
    "df_clean.loc[df_clean[\"End\"] < df_clean[\"Start\"], \"End\"] += pd.Timedelta(days=1)\n",
    "\n",
    "# Outage-Events: alle Zeilen mit Downtime > 0\n",
    "df_out = df_clean[df_clean[\"Downtime_min\"] > 0].copy()\n",
    "\n",
    "print(\"Events (Downtime>0):\", df_out.shape[0])\n",
    "print(\"Zeitraum:\", df_out[\"Datum\"].min(), \"bis\", df_out[\"Datum\"].max())\n",
    "df_out[[\"Datum\",\"Schicht\",\"Zeit von\",\"Zeit bis\",\"Downtime_min\"]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa84ce4",
   "metadata": {},
   "source": [
    "## 1) Überblick / KPIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0846c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "kpi = {\n",
    "    \"Events (Downtime>0)\": int(df_out.shape[0]),\n",
    "    \"Gesamte Downtime (min)\": float(df_out[\"Downtime_min\"].sum()),\n",
    "    \"Ø Downtime je Event (min)\": float(df_out[\"Downtime_min\"].mean()),\n",
    "    \"Median Downtime (min)\": float(df_out[\"Downtime_min\"].median()),\n",
    "}\n",
    "pd.DataFrame([kpi])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea079403",
   "metadata": {},
   "source": [
    "## 2) Stoßzeiten (wann passieren Ausfälle?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17dc689",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[\"Start_hour\"] = df_out[\"Start\"].dt.hour\n",
    "hour_stats = (df_out.dropna(subset=[\"Start_hour\"])\n",
    "              .groupby(\"Start_hour\")\n",
    "              .agg(events=(\"Downtime_min\",\"size\"),\n",
    "                   downtime_min=(\"Downtime_min\",\"sum\"),\n",
    "                   avg_downtime=(\"Downtime_min\",\"mean\"))\n",
    "              .reset_index()\n",
    "              .sort_values(\"Start_hour\"))\n",
    "\n",
    "display(hour_stats)\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(hour_stats[\"Start_hour\"], hour_stats[\"events\"])\n",
    "plt.title(\"Anzahl Ausfälle nach Start-Stunde\")\n",
    "plt.xlabel(\"Stunde (0-23)\")\n",
    "plt.ylabel(\"Anzahl Events\")\n",
    "plt.xticks(range(0,24,1))\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(hour_stats[\"Start_hour\"], hour_stats[\"downtime_min\"])\n",
    "plt.title(\"Gesamte Downtime (min) nach Start-Stunde\")\n",
    "plt.xlabel(\"Stunde (0-23)\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.xticks(range(0,24,1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450f6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap: Wochentag x Stunde (Event-Anzahl)\n",
    "df_out[\"DayName\"] = df_out[\"Datum\"].dt.day_name()\n",
    "order = [\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\",\"Sunday\"]\n",
    "\n",
    "heat = (df_out.pivot_table(index=\"DayName\", columns=\"Start_hour\", values=\"Downtime_min\",\n",
    "                           aggfunc=\"size\", fill_value=0)\n",
    "        .reindex(order))\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.imshow(heat.values, aspect=\"auto\")\n",
    "plt.title(\"Heatmap: Anzahl Ausfälle (Wochentag x Stunde)\")\n",
    "plt.yticks(range(len(heat.index)), heat.index)\n",
    "plt.xticks(range(0,24,1), range(0,24,1))\n",
    "plt.xlabel(\"Stunde\")\n",
    "plt.colorbar(label=\"Anzahl Events\")\n",
    "plt.show()\n",
    "\n",
    "display(heat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8de97d",
   "metadata": {},
   "source": [
    "## 3) Welche Maschinen/Stationen haben die meisten Fehler?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed04a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out[\"Station_norm\"] = (df_out[\"Station/ OP\"].astype(\"string\")\n",
    "                          .str.upper()\n",
    "                          .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "                          .str.strip())\n",
    "\n",
    "station_stats = (df_out.groupby(\"Station_norm\")\n",
    "                 .agg(events=(\"Downtime_min\",\"size\"),\n",
    "                      downtime_min=(\"Downtime_min\",\"sum\"),\n",
    "                      avg_downtime=(\"Downtime_min\",\"mean\"))\n",
    "                 .sort_values([\"events\",\"downtime_min\"], ascending=False))\n",
    "\n",
    "display(station_stats.head(20))\n",
    "\n",
    "top10 = station_stats.head(10).reset_index()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(top10[\"Station_norm\"], top10[\"events\"])\n",
    "plt.title(\"Top 10 Stationen nach Anzahl Events\")\n",
    "plt.xlabel(\"Station\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.bar(top10[\"Station_norm\"], top10[\"downtime_min\"])\n",
    "plt.title(\"Top 10 Stationen nach gesamter Downtime\")\n",
    "plt.xlabel(\"Station\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685876f2",
   "metadata": {},
   "source": [
    "## 4) Welche Fehler/Ursachen wie oft? (Unterbrechungsursache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7e85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cause_stats = (df_out.groupby(\"Unterbrechungsursache\")\n",
    "               .agg(events=(\"Downtime_min\",\"size\"),\n",
    "                    total_downtime=(\"Downtime_min\",\"sum\"),\n",
    "                    avg_downtime=(\"Downtime_min\",\"mean\"),\n",
    "                    median_downtime=(\"Downtime_min\",\"median\"))\n",
    "               .sort_values(\"events\", ascending=False))\n",
    "\n",
    "display(cause_stats.head(20))\n",
    "\n",
    "top_causes = cause_stats.head(12).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(top_causes[\"Unterbrechungsursache\"].astype(str), top_causes[\"events\"])\n",
    "plt.title(\"Top Ursachen nach Häufigkeit\")\n",
    "plt.xlabel(\"Unterbrechungsursache\")\n",
    "plt.ylabel(\"Events\")\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "plt.show()\n",
    "\n",
    "top_causes_downtime = cause_stats.sort_values(\"total_downtime\", ascending=False).head(12).reset_index()\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.bar(top_causes_downtime[\"Unterbrechungsursache\"].astype(str), top_causes_downtime[\"total_downtime\"])\n",
    "plt.title(\"Top Ursachen nach gesamter Downtime\")\n",
    "plt.xlabel(\"Unterbrechungsursache\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.xticks(rotation=60, ha=\"right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38be261e",
   "metadata": {},
   "source": [
    "## 5) Auffälligkeiten bei der Ausfalldauer (Kombinationen, Ausreißer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c2534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verteilung der Downtime\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.hist(df_out[\"Downtime_min\"].dropna(), bins=30)\n",
    "plt.title(\"Verteilung: Downtime je Event (min)\")\n",
    "plt.xlabel(\"Downtime (min)\")\n",
    "plt.ylabel(\"Anzahl Events\")\n",
    "plt.show()\n",
    "\n",
    "# Downtime nach Schicht (Boxplot)\n",
    "plt.figure(figsize=(8,4))\n",
    "data = [df_out.loc[df_out[\"Schicht\"]==s, \"Downtime_min\"].dropna() for s in sorted(df_out[\"Schicht\"].dropna().unique())]\n",
    "labels = [s for s in sorted(df_out[\"Schicht\"].dropna().unique())]\n",
    "plt.boxplot(data, labels=labels, showfliers=False)\n",
    "plt.title(\"Downtime je Event nach Schicht (ohne Ausreißer)\")\n",
    "plt.xlabel(\"Schicht\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.show()\n",
    "\n",
    "# Ausreißer: Top 20 längste Events\n",
    "top_long = (df_out.sort_values(\"Downtime_min\", ascending=False)\n",
    "            .loc[:, [\"Datum\",\"Start\",\"End\",\"Schicht\",\"Station_norm\",\"Unterbrechungsursache\",\"Downtime_min\",\"Bemerkung\"]]\n",
    "            .head(20))\n",
    "display(top_long)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244b4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenhang mit Output / Personal (wenn vorhanden)\n",
    "num_cols = [\"Downtime_min\", \"Dauer Arbeits-zeit\", \"Anzahl MA\", \"Menge N.i. O.\", \"Profi\", \"AHV\", \"Menge Gesamt (Stück)\"]\n",
    "corr = df_out[num_cols].corr(method=\"spearman\", numeric_only=True)\n",
    "display(corr)\n",
    "\n",
    "# Scatter: Downtime vs Menge Gesamt\n",
    "plt.figure(figsize=(6,4))\n",
    "x = df_out[\"Menge Gesamt (Stück)\"]\n",
    "y = df_out[\"Downtime_min\"]\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.title(\"Downtime vs. Menge Gesamt (Stück)\")\n",
    "plt.xlabel(\"Menge Gesamt (Stück)\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.show()\n",
    "\n",
    "# Scatter: Downtime vs Anzahl MA\n",
    "plt.figure(figsize=(6,4))\n",
    "x = df_out[\"Anzahl MA\"]\n",
    "y = df_out[\"Downtime_min\"]\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.title(\"Downtime vs. Anzahl MA\")\n",
    "plt.xlabel(\"Anzahl MA\")\n",
    "plt.ylabel(\"Downtime (min)\")\n",
    "plt.show()\n",
    "\n",
    "# Aggregation nach Anzahl MA\n",
    "ma_stats = (df_out.groupby(\"Anzahl MA\")\n",
    "            .agg(events=(\"Downtime_min\",\"size\"),\n",
    "                 avg_downtime=(\"Downtime_min\",\"mean\"),\n",
    "                 total_downtime=(\"Downtime_min\",\"sum\"))\n",
    "            .sort_index())\n",
    "display(ma_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1ce5b",
   "metadata": {},
   "source": [
    "## 6) Ideen für nächste Schritte\n",
    "\n",
    "- **Freitext reduzieren:** „Freitext“ ist sehr häufig – ideal wäre eine standardisierte Fehlerklassifikation (Dropdown).\n",
    "- **Stationen konsolidieren:** z.B. `R 06` vs. `R06` (falls vorhanden) vereinheitlichen.\n",
    "- **Ausfälle nach Priorität:** Fokus auf Kombination aus **hoher Downtime** + **hoher Häufigkeit** (Pareto).\n",
    "- **Geplante vs. ungeplante Stops:** Ursachen wie „Wartungsplan“/„Reinigung“ ggf. separat betrachten.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
